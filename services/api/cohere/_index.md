---
title: Cohere - API
weight: 5
comments: true
sidebar:
  open: true
---

## ğŸ“‹ æœåŠ¡ä¿¡æ¯

**æä¾›è€…ï¼š** [Cohere](/providers/cohere)  
**æœåŠ¡ç±»å‹ï¼š** API æœåŠ¡  
**API ç«¯ç‚¹ï¼š** [https://api.cohere.ai](https://api.cohere.ai)  
**å…è´¹ç±»å‹ï¼š** Trial 1,000 calls/æœˆï¼ŒProduction 10,000 calls/æœˆ

---

## ğŸ¯ æœåŠ¡ç®€ä»‹

Cohere API æä¾›ä¼ä¸šçº§ AI èƒ½åŠ›ï¼Œç‰¹åˆ«æ“…é•¿ RAGã€Embedding å’Œ Rerankï¼Œæ˜¯æ„å»ºæ™ºèƒ½æœç´¢å’ŒçŸ¥è¯†åº“çš„é¦–é€‰ã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- ğŸ¯ **RAG ä¸“å®¶** - ä¸šç•Œé¢†å…ˆçš„æ£€ç´¢å¢å¼ºç”Ÿæˆ
- ğŸ“Š **å¼ºå¤§ Embedding** - é¡¶å°–æ–‡æœ¬å‘é‡åŒ–
- ğŸ” **æœ€ä½³ Rerank** - æå‡æœç´¢å‡†ç¡®åº¦ 20-30%
- ğŸŒ **å¤šè¯­è¨€** - 100+ è¯­è¨€æ”¯æŒ
- ğŸ’¼ **ä¼ä¸šçº§** - Production 10,000 calls/æœˆ
- ğŸ†“ **å…è´¹å¼€å§‹** - Trial 1,000 calls/æœˆï¼Œæ— éœ€ä¿¡ç”¨å¡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ææ¡ä»¶

**Trial å±‚çº§ï¼ˆæ¨èï¼‰ï¼š**
- âœ… å·²æ³¨å†Œ Cohere è´¦æˆ·
- âŒ æ— éœ€ä¿¡ç”¨å¡

**Production å±‚çº§ï¼š**
- âœ… å·²æ³¨å†Œ Cohere è´¦æˆ·
- âœ… å·²éªŒè¯ä¿¡ç”¨å¡ï¼ˆä¸æ‰£è´¹ï¼‰

è¯¦ç»†æ­¥éª¤è¯·å‚è€ƒï¼š[Cohere æ³¨å†ŒæŒ‡å—](/providers/cohere#æ³¨å†Œå’Œè´¦å·)

### 5 åˆ†é’Ÿå¿«é€Ÿç¤ºä¾‹

**å®‰è£… SDKï¼š**
```bash {filename="Bash"}
pip install cohere
```

**åŸºç¡€å¯¹è¯ï¼š**
```python {filename="Python"}
import cohere

# åˆå§‹åŒ–å®¢æˆ·ç«¯
co = cohere.Client('YOUR_API_KEY')

# ä½¿ç”¨ Command R+ å¯¹è¯
response = co.chat(
    message="ä»€ä¹ˆæ˜¯ RAGï¼Ÿè¯·ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šã€‚",
    model="command-r-plus"
)

print(response.text)
```

---

## ğŸ¤– æ ¸å¿ƒæ¨¡å‹å’ŒåŠŸèƒ½

### 1. Chat - å¯¹è¯ç”Ÿæˆ

**Command R+ æ¨¡å‹ï¼š**
- 128K ä¸Šä¸‹æ–‡çª—å£
- RAG ä¼˜åŒ–
- 100+ è¯­è¨€æ”¯æŒ

**åŸºç¡€ä½¿ç”¨ï¼š**
```python {filename="Python"}
response = co.chat(
    message="ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ Cohere",
    model="command-r-plus"
)
print(response.text)
```

**å¸¦ RAG çš„å¯¹è¯ï¼š**
```python {filename="Python"}
# åŸºäºæ–‡æ¡£çš„å¯¹è¯
response = co.chat(
    message="æ€»ç»“ä¸€ä¸‹è¿™äº›æ–‡æ¡£çš„è¦ç‚¹",
    documents=[
        {
            "title": "AI å‘å±•", 
            "text": "äººå·¥æ™ºèƒ½è¿‘å¹´æ¥å‘å±•è¿…é€Ÿ..."
        },
        {
            "title": "RAG æŠ€æœ¯", 
            "text": "æ£€ç´¢å¢å¼ºç”Ÿæˆæ˜¯ä¸€ç§..."
        }
    ],
    model="command-r-plus"
)

print(response.text)

# æŸ¥çœ‹å¼•ç”¨çš„æ–‡æ¡£
for citation in response.citations:
    print(f"å¼•ç”¨: {citation['text']}")
```

### 2. Embed - æ–‡æœ¬å‘é‡åŒ–

**åŠŸèƒ½ï¼š**
- å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
- è¯­ä¹‰æœç´¢
- æ–‡æœ¬èšç±»å’Œåˆ†ç±»

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python {filename="Python"}
texts = [
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
    "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ",
    "RAG ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆ"
]

response = co.embed(
    texts=texts,
    model="embed-multilingual-v3.0",
    input_type="search_document"
)

print(f"å‘é‡ç»´åº¦: {len(response.embeddings[0])}")
print(f"ç¬¬ä¸€ä¸ªæ–‡æœ¬çš„å‘é‡: {response.embeddings[0][:5]}...")
```

**è¯­ä¹‰æœç´¢ç¤ºä¾‹ï¼š**
```python {filename="Python"}
import numpy as np

# 1. å‡†å¤‡æ–‡æ¡£
documents = [
    "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€",
    "æœºå™¨å­¦ä¹ ä½¿ç”¨ç®—æ³•ä»æ•°æ®ä¸­å­¦ä¹ ",
    "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
    "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ"
]

# 2. ç”Ÿæˆæ–‡æ¡£å‘é‡
doc_embeddings = co.embed(
    texts=documents,
    model="embed-multilingual-v3.0",
    input_type="search_document"
).embeddings

# 3. ç”ŸæˆæŸ¥è¯¢å‘é‡
query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
query_embedding = co.embed(
    texts=[query],
    model="embed-multilingual-v3.0",
    input_type="search_query"
).embeddings[0]

# 4. è®¡ç®—ç›¸ä¼¼åº¦
scores = [
    np.dot(query_embedding, doc_emb)
    for doc_emb in doc_embeddings
]

# 5. æ’åºå¹¶æ˜¾ç¤ºç»“æœ
for idx in np.argsort(scores)[::-1]:
    print(f"{documents[idx]}: {scores[idx]:.4f}")
```

### 3. Rerank - æœç´¢ç»“æœé‡æ’åº

**åŠŸèƒ½ï¼š**
- å¯¹æœç´¢ç»“æœé‡æ–°æ’åº
- æå‡å‡†ç¡®åº¦ 20-30%
- RAG å¿…å¤‡å·¥å…·

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python {filename="Python"}
query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
documents = [
    "æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
    "ä»Šå¤©å¤©æ°”ä¸é”™",
    "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ",
    "æˆ‘å–œæ¬¢åƒæŠ«è¨"
]

response = co.rerank(
    query=query,
    documents=documents,
    model="rerank-multilingual-v3.0",
    top_n=2
)

# æ˜¾ç¤ºé‡æ’åºåçš„ç»“æœ
for result in response.results:
    print(f"ç›¸å…³åº¦ {result.relevance_score:.4f}: {documents[result.index]}")
```

---

## ğŸ”¢ é…é¢å’Œå®šä»·

### Trial å±‚çº§ï¼ˆå…è´¹ï¼‰

| é¡¹ç›® | é…é¢ | è¯´æ˜ |
|------|------|------|
| æœˆåº¦è°ƒç”¨ | 1,000 calls | æ— éœ€ä¿¡ç”¨å¡ |
| é€Ÿç‡é™åˆ¶ | 10 req/min | å¼€å‘æµ‹è¯• |
| å¯ç”¨æ¨¡å‹ | å…¨éƒ¨ | Chat, Embed, Rerank |

### Production å±‚çº§ï¼ˆå…è´¹ï¼‰

| é¡¹ç›® | é…é¢ | è¯´æ˜ |
|------|------|------|
| æœˆåº¦è°ƒç”¨ | 10,000 calls | éœ€éªŒè¯ä¿¡ç”¨å¡ |
| é€Ÿç‡é™åˆ¶ | 1,000 req/min | ç”Ÿäº§çº§æ€§èƒ½ |
| å¯ç”¨æ¨¡å‹ | å…¨éƒ¨ | æ‰€æœ‰ä¼ä¸šåŠŸèƒ½ |

### API è°ƒç”¨è®¡æ•°

- **Chatï¼š** æ¯æ¬¡è¯·æ±‚ = 1 call
- **Embedï¼š** æ¯ 1,000 texts = 1 call
- **Rerankï¼š** æ¯æ¬¡è¯·æ±‚ = 1 call

---

## ğŸ’¡ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **æ„å»º RAG ç³»ç»Ÿ**
   ```python
   # å®Œæ•´ RAG æµç¨‹
   # 1. Embed - å‘é‡åŒ–æ–‡æ¡£
   # 2. è¯­ä¹‰æœç´¢ - æ‰¾åˆ°ç›¸å…³æ–‡æ¡£
   # 3. Rerank - é‡æ’åºç»“æœ
   # 4. Chat - åŸºäºæ–‡æ¡£ç”Ÿæˆå›ç­”
   
   # æ­¥éª¤ 1: å‘é‡åŒ–
   doc_embeddings = co.embed(
       texts=documents,
       model="embed-multilingual-v3.0",
       input_type="search_document"
   ).embeddings
   
   # æ­¥éª¤ 2: æœç´¢ï¼ˆä½¿ç”¨å‘é‡æ•°æ®åº“å¦‚ Pineconeï¼‰
   relevant_docs = search_vector_db(query, doc_embeddings)
   
   # æ­¥éª¤ 3: é‡æ’åº
   reranked = co.rerank(
       query=query,
       documents=relevant_docs,
       model="rerank-multilingual-v3.0",
       top_n=5
   )
   
   # æ­¥éª¤ 4: ç”Ÿæˆå›ç­”
   response = co.chat(
       message=query,
       documents=[{"text": doc} for doc in reranked.results],
       model="command-r-plus"
   )
   ```

2. **ä¼˜åŒ– API è°ƒç”¨**
   ```python
   # Embed å¾ˆåˆ’ç®—ï¼š1,000 texts = 1 call
   # æ‰¹é‡å¤„ç†æ–‡æœ¬
   large_batch = ["text1", "text2", ..., "text1000"]
   embeddings = co.embed(
       texts=large_batch,
       model="embed-multilingual-v3.0"
   )  # åªæ¶ˆè€— 1 call
   ```

3. **é”™è¯¯å¤„ç†**
   ```python
   import time
   
   def call_with_retry(func, max_retries=3):
       for i in range(max_retries):
           try:
               return func()
           except Exception as e:
               if i < max_retries - 1:
                   wait_time = 2 ** i
                   print(f"é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’...")
                   time.sleep(wait_time)
               else:
                   raise
   ```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. Trial å’Œ Production çš„åŒºåˆ«ï¼Ÿ

**ä¸»è¦åŒºåˆ«ï¼š**
| ç‰¹æ€§ | Trial | Production |
|------|-------|------------|
| é…é¢ | 1,000 calls/æœˆ | 10,000 calls/æœˆ |
| é€Ÿç‡ | 10 req/min | 1,000 req/min |
| ä¿¡ç”¨å¡ | ä¸éœ€è¦ | éœ€è¦éªŒè¯ |
| æ‰£è´¹ | ä¸ä¼š | å…è´¹é…é¢å†…ä¸ä¼š |

### 2. å¦‚ä½•å‡çº§åˆ° Productionï¼Ÿ

**æ­¥éª¤ï¼š**
1. ç™»å½• Dashboard
2. é€‰æ‹© "Upgrade to Production"
3. æ·»åŠ ä¿¡ç”¨å¡ï¼ˆä»…éªŒè¯ï¼Œä¸æ‰£è´¹ï¼‰
4. è‡ªåŠ¨å‡çº§

### 3. Embed ä¸ºä»€ä¹ˆè¿™ä¹ˆåˆ’ç®—ï¼Ÿ

**è®¡è´¹æ–¹å¼ï¼š**
- æ¯ 1,000 texts = 1 call
- ä¾‹å¦‚ï¼šå‘é‡åŒ– 5,000 ä¸ªæ–‡æ¡£ = 5 calls
- éå¸¸é€‚åˆå¤§è§„æ¨¡æ–‡æœ¬å¤„ç†

### 4. å¦‚ä½•æŸ¥çœ‹å‰©ä½™é…é¢ï¼Ÿ

**æ–¹æ³•ï¼š**
- ç™»å½• https://dashboard.cohere.com
- Dashboard é¦–é¡µæ˜¾ç¤ºå½“æœˆä½¿ç”¨æƒ…å†µ

---

## ğŸ“š ç›¸å…³èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Cohere å®Œæ•´ä»‹ç»](/providers/cohere)
- [Coral Chatbot ä½¿ç”¨æŒ‡å—](/services/chatbot/cohere-coral)
- [API å®˜æ–¹æ–‡æ¡£](https://docs.cohere.com)

### å·¥å…·å’Œèµ„æº
- [Python SDK](https://github.com/cohere-ai/cohere-python)
- [ç¤ºä¾‹ä»£ç ](https://github.com/cohere-ai/notebooks)
- [Discord ç¤¾åŒº](https://discord.gg/co-mmunity)

---

## ğŸŒŸ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šæ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

```python {filename="Python"}
import cohere

co = cohere.Client('YOUR_API_KEY')

class DocumentQA:
    def __init__(self, documents):
        self.documents = documents
        # å‘é‡åŒ–æ–‡æ¡£
        self.embeddings = co.embed(
            texts=documents,
            model="embed-multilingual-v3.0",
            input_type="search_document"
        ).embeddings
    
    def ask(self, question):
        # 1. æœç´¢ç›¸å…³æ–‡æ¡£
        query_emb = co.embed(
            texts=[question],
            model="embed-multilingual-v3.0",
            input_type="search_query"
        ).embeddings[0]
        
        # 2. è®¡ç®—ç›¸ä¼¼åº¦å¹¶å– top 5
        scores = [np.dot(query_emb, doc_emb) for doc_emb in self.embeddings]
        top_indices = np.argsort(scores)[-5:][::-1]
        relevant_docs = [self.documents[i] for i in top_indices]
        
        # 3. Rerank ç²¾æ’
        reranked = co.rerank(
            query=question,
            documents=relevant_docs,
            model="rerank-multilingual-v3.0",
            top_n=3
        )
        
        # 4. ç”Ÿæˆå›ç­”
        response = co.chat(
            message=question,
            documents=[{"text": relevant_docs[r.index]} for r in reranked.results],
            model="command-r-plus"
        )
        
        return response.text

# ä½¿ç”¨
docs = ["æ–‡æ¡£1å†…å®¹...", "æ–‡æ¡£2å†…å®¹...", "æ–‡æ¡£3å†…å®¹..."]
qa_system = DocumentQA(docs)
answer = qa_system.ask("è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(answer)
```

### æ¡ˆä¾‹ 2ï¼šè¯­ä¹‰æœç´¢å¼•æ“

```python {filename="Python"}
class SemanticSearch:
    def __init__(self, documents):
        self.documents = documents
        self.embeddings = co.embed(
            texts=documents,
            model="embed-multilingual-v3.0",
            input_type="search_document"
        ).embeddings
    
    def search(self, query, top_k=5):
        # 1. å‘é‡æœç´¢
        query_emb = co.embed(
            texts=[query],
            model="embed-multilingual-v3.0",
            input_type="search_query"
        ).embeddings[0]
        
        scores = [np.dot(query_emb, doc_emb) for doc_emb in self.embeddings]
        top_indices = np.argsort(scores)[-top_k*2:][::-1]
        candidates = [self.documents[i] for i in top_indices]
        
        # 2. Rerank ç²¾æ’
        reranked = co.rerank(
            query=query,
            documents=candidates,
            model="rerank-multilingual-v3.0",
            top_n=top_k
        )
        
        # 3. è¿”å›ç»“æœ
        results = []
        for result in reranked.results:
            results.append({
                "document": candidates[result.index],
                "score": result.relevance_score
            })
        
        return results

# ä½¿ç”¨
search_engine = SemanticSearch(documents)
results = search_engine.search("æœºå™¨å­¦ä¹ ç›¸å…³å†…å®¹", top_k=3)
for r in results:
    print(f"{r['score']:.4f}: {r['document'][:100]}...")
```

---

**æœåŠ¡æä¾›è€…ï¼š** [Cohere](/providers/cohere)
