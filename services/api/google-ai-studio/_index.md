---
title: Google AI Studio - API
weight: 1
comments: true
sidebar:
  open: true
---

## ğŸ“‹ æœåŠ¡ä¿¡æ¯

**æä¾›è€…ï¼š** [Google AI Studio](/providers/google-ai-studio)  
**æœåŠ¡ç±»å‹ï¼š** API æœåŠ¡  
**API ç«¯ç‚¹ï¼š** [https://generativelanguage.googleapis.com](https://generativelanguage.googleapis.com)  
**å…è´¹ç±»å‹ï¼š** æ°¸ä¹…å…è´¹ï¼ˆæœ‰ä½¿ç”¨é™åˆ¶ï¼‰

---

## ğŸ¯ æœåŠ¡ç®€ä»‹

Google AI Studio çš„ API æœåŠ¡æä¾›äº†å¼ºå¤§çš„ Gemini æ¨¡å‹è®¿é—®èƒ½åŠ›ï¼Œå®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼ï¼Œè®©å¼€å‘è€…å¯ä»¥è½»æ¾é›†æˆåˆ°è‡ªå·±çš„åº”ç”¨ä¸­ã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- ğŸ **è¶…é«˜å…è´¹é…é¢** - 15M tokens/å¤©ï¼ˆFlash ç³»åˆ—ï¼‰
- âš¡ **æå¿«å“åº”é€Ÿåº¦** - Flash ç³»åˆ—ä¼˜åŒ–
- ğŸ”„ **OpenAI å…¼å®¹** - æ— ç¼è¿ç§»ç°æœ‰ä»£ç 
- ğŸ¨ **å¤šæ¨¡æ€ API** - æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘
- ğŸ“± **è¶…é•¿ä¸Šä¸‹æ–‡** - æœ€é«˜ 2M tokens
- ğŸ” **è”ç½‘æœç´¢** - Google Search Grounding

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ææ¡ä»¶

**å¿…éœ€ï¼š**
- âœ… å·²åˆ›å»º API å¯†é’¥

è¯¦ç»†æ­¥éª¤è¯·å‚è€ƒï¼š[Google AI Studio æ³¨å†ŒæŒ‡å—](/providers/google-ai-studio#æ³¨å†Œå’Œè´¦å·)

### è·å– API å¯†é’¥

1. è®¿é—®ï¼šhttps://aistudio.google.com
2. å·¦ä¾§èœå•ç‚¹å‡» "Get API key"
3. é€‰æ‹©æˆ–åˆ›å»º Google Cloud é¡¹ç›®
4. ç‚¹å‡» "Create API key"
5. **ç«‹å³å¤åˆ¶å¹¶ä¿å­˜å¯†é’¥**

### 5 åˆ†é’Ÿå¿«é€Ÿç¤ºä¾‹

**Python ç¤ºä¾‹ï¼š**

```python {filename="Python"}
import google.generativeai as genai

# é…ç½® API å¯†é’¥
genai.configure(api_key="YOUR_API_KEY")

# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = genai.GenerativeModel('gemini-2.5-flash')

# å‘é€è¯·æ±‚
response = model.generate_content("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
print(response.text)
```

**cURL ç¤ºä¾‹ï¼š**

```bash {filename="Bash"}
curl https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=YOUR_API_KEY \
  -H 'Content-Type: application/json' \
  -d '{
    "contents": [{
      "parts":[{"text": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]
    }]
  }'
```

---

## ğŸ¤– æ”¯æŒçš„æ¨¡å‹

### Gemini Flash ç³»åˆ—ï¼ˆæ¨èï¼‰

| æ¨¡å‹åç§° | æ¨¡å‹ ID | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|---------|------|---------|
| **Gemini 3 Flash** | `gemini-3-flash` | æœ€å¿«é€Ÿåº¦ | é«˜é¢‘è°ƒç”¨ã€å®æ—¶å“åº” |
| **Gemini 2.5 Flash** | `gemini-2.5-flash` | æ–°ä¸€ä»£å¿«é€Ÿæ¨¡å‹ | æ—¥å¸¸ä»»åŠ¡ã€å¹³è¡¡æ€§èƒ½ |
| **Gemini 2.5 Flash-Lite** | `gemini-2.5-flash-lite` | è½»é‡è¶…å¿« | ç®€å•ä»»åŠ¡ã€æé€Ÿå“åº” |

### Gemini Pro ç³»åˆ—

| æ¨¡å‹åç§° | æ¨¡å‹ ID | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|---------|------|---------|
| **Gemini Pro** | `gemini-pro` | æ›´å¼ºç†è§£ | å¤æ‚ä»»åŠ¡ã€æ·±åº¦æ¨ç† |

### Gemma å¼€æºç³»åˆ—

| æ¨¡å‹åç§° | æ¨¡å‹ ID | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|---------|------|---------|
| **Gemma 3 27B** | `gemma-3-27b-instruct` | å¤§å‚æ•°é‡ | å¤æ‚ä»»åŠ¡ |
| **Gemma 3 12B** | `gemma-3-12b-instruct` | ä¸­ç­‰å‚æ•° | å¹³è¡¡æ€§èƒ½ |
| **Gemma 3 4B** | `gemma-3-4b-instruct` | å°å‹å¿«é€Ÿ | è½»é‡ä»»åŠ¡ |

---

## ğŸ”¢ é…é¢å’Œé™åˆ¶

### API é…é¢é™åˆ¶

| æ¨¡å‹åç§° | æ¯æ—¥è¯·æ±‚æ•° | æ¯åˆ†é’Ÿè¯·æ±‚æ•° | æ¯åˆ†é’Ÿ Tokens |
|---------|-----------|-------------|--------------|
| Gemini 3 Flash | 20 requests/day | 5 requests/min | 250,000 tokens/min |
| Gemini 2.5 Flash | 20 requests/day | 5 requests/min | 250,000 tokens/min |
| Gemini 2.5 Flash-Lite | 20 requests/day | 10 requests/min | 250,000 tokens/min |
| Gemma 3 27B | 14,400 requests/day | 30 requests/min | 15,000 tokens/min |
| Gemma 3 12B | 14,400 requests/day | 30 requests/min | 15,000 tokens/min |
| Gemma 3 4B | 14,400 requests/day | 30 requests/min | 15,000 tokens/min |

### æ¯æ—¥æ€»é…é¢

| æ¨¡å‹ç³»åˆ— | æ¯æ—¥ Tokens é…é¢ |
|---------|----------------|
| Gemini Flash ç³»åˆ— | 15M tokens |
| Gemini Pro ç³»åˆ— | 3M tokens |
| Gemma ç³»åˆ— | 4M tokens |

### ä¸Šä¸‹æ–‡é•¿åº¦

| æ¨¡å‹ | è¾“å…¥ä¸Šä¸‹æ–‡ | è¾“å‡ºé•¿åº¦ |
|------|-----------|---------|
| Gemini ç³»åˆ— | æœ€é«˜ 2M tokens | 8,192 tokens |
| Gemma ç³»åˆ— | 8K-128K tokens | 8,192 tokens |

### âš ï¸ é‡è¦é™åˆ¶

1. **æ€»è¯·æ±‚é™åˆ¶ï¼š** æ‰€æœ‰ Gemini æ¨¡å‹å…±äº«æ¯æ—¥ 1500 æ¬¡è¯·æ±‚çš„æ€»é…é¢
2. **è·¨æ¨¡å‹é€Ÿç‡é™åˆ¶ï¼š** 60 requests/minï¼ˆè·¨æ‰€æœ‰æ¨¡å‹ï¼‰
3. **é…é¢å…±äº«ï¼š** æ‰€æœ‰ API å¯†é’¥å…±äº«åŒä¸€ä¸ª GCP é¡¹ç›®çš„é…é¢

---

## ğŸ“– API ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€æ–‡æœ¬ç”Ÿæˆ

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-flash')

# ç®€å•å¯¹è¯
response = model.generate_content("è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")
print(response.text)

# å¸¦å‚æ•°çš„è¯·æ±‚
response = model.generate_content(
    "å†™ä¸€é¦–å…³äºç§‹å¤©çš„è¯—",
    generation_config={
        "temperature": 0.9,
        "top_p": 0.95,
        "max_output_tokens": 1024,
    }
)
print(response.text)
```

**REST APIï¼š**

```bash {filename="Bash"}
curl https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=YOUR_API_KEY \
  -H 'Content-Type: application/json' \
  -d '{
    "contents": [{
      "parts":[{"text": "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "}]
    }],
    "generationConfig": {
      "temperature": 0.7,
      "maxOutputTokens": 1024
    }
  }'
```

### 2. å¤šè½®å¯¹è¯

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-flash')

# åˆ›å»ºå¯¹è¯ä¼šè¯
chat = model.start_chat(history=[])

# ç¬¬ä¸€è½®å¯¹è¯
response = chat.send_message("ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹  Python")
print(response.text)

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆæ¨¡å‹ä¼šè®°ä½ä¸Šä¸‹æ–‡ï¼‰
response = chat.send_message("åº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ")
print(response.text)

# æŸ¥çœ‹å¯¹è¯å†å²
print(chat.history)
```

### 3. å›¾åƒç†è§£

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai
from PIL import Image

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-flash')

# åŠ è½½å›¾ç‰‡
image = Image.open('example.jpg')

# å‘é€å›¾ç‰‡å’Œé—®é¢˜
response = model.generate_content([
    "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿè¯·è¯¦ç»†æè¿°ã€‚",
    image
])
print(response.text)
```

**ä» URL åŠ è½½å›¾ç‰‡ï¼š**

```python {filename="Python"}
import google.generativeai as genai
from PIL import Image
import requests
from io import BytesIO

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-flash')

# ä» URL åŠ è½½å›¾ç‰‡
response = requests.get('https://example.com/image.jpg')
image = Image.open(BytesIO(response.content))

# åˆ†æå›¾ç‰‡
response = model.generate_content(["åˆ†æè¿™å¼ å›¾ç‰‡", image])
print(response.text)
```

### 4. æµå¼è¾“å‡º

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-flash')

# æµå¼è¾“å‡º
response = model.generate_content(
    "å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ",
    stream=True
)

for chunk in response:
    print(chunk.text, end='')
```

### 5. å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

# å®šä¹‰å‡½æ•°
def get_weather(city: str):
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”"""
    # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„å¤©æ°” API
    return f"{city}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œ25Â°C"

# å®šä¹‰å‡½æ•°æè¿°
tools = [{
    "function_declarations": [{
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {
                    "type": "string",
                    "description": "åŸå¸‚åç§°"
                }
            },
            "required": ["city"]
        }
    }]
}]

model = genai.GenerativeModel(
    'gemini-2.5-flash',
    tools=tools
)

# å‘é€è¯·æ±‚
chat = model.start_chat()
response = chat.send_message("ä¸Šæµ·ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")

# æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°
if response.candidates[0].content.parts[0].function_call:
    function_call = response.candidates[0].content.parts[0].function_call
    
    # è°ƒç”¨å‡½æ•°
    if function_call.name == "get_weather":
        result = get_weather(function_call.args["city"])
        
        # å°†ç»“æœè¿”å›ç»™æ¨¡å‹
        response = chat.send_message({
            "function_response": {
                "name": "get_weather",
                "response": {"result": result}
            }
        })
        print(response.text)
```

### 6. Google Search Grounding

**Python SDKï¼š**

```python {filename="Python"}
import google.generativeai as genai

genai.configure(api_key="YOUR_API_KEY")

# å¯ç”¨ Google Search Grounding
model = genai.GenerativeModel('gemini-2.5-flash')

response = model.generate_content(
    "æœ€æ–°çš„ AI æŠ€æœ¯å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
    tools=[{"google_search_retrieval": {}}]
)

print(response.text)

# æŸ¥çœ‹å¼•ç”¨æ¥æº
for candidate in response.candidates:
    if hasattr(candidate, 'grounding_metadata'):
        print("\nå¼•ç”¨æ¥æºï¼š")
        for attribution in candidate.grounding_metadata.grounding_attributions:
            print(f"- {attribution.source_id.grounding_passage.url}")
```

---

## ğŸ› ï¸ SDK å’Œå®¢æˆ·ç«¯åº“

### å®˜æ–¹ SDK

**Pythonï¼š**
```bash {filename="Bash"}
pip install google-generativeai
```

**Node.jsï¼š**
```bash {filename="Bash"}
npm install @google/generative-ai
```

**Goï¼š**
```bash {filename="Bash"}
go get github.com/google/generative-ai-go
```

### OpenAI å…¼å®¹

Google AI Studio API å…¼å®¹ OpenAI æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ OpenAI SDKï¼š

```python {filename="Python"}
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_GOOGLE_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[
        {"role": "user", "content": "ä½ å¥½"}
    ]
)

print(response.choices[0].message.content)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**
   - é«˜é¢‘è°ƒç”¨ï¼šGemini 3 Flashï¼ˆæœ€å¿«ï¼‰
   - æ—¥å¸¸ä»»åŠ¡ï¼šGemini 2.5 Flashï¼ˆå¹³è¡¡ï¼‰
   - å¤æ‚ä»»åŠ¡ï¼šGemini Proï¼ˆæ›´å¼ºï¼‰
   - å¼€æºéœ€æ±‚ï¼šGemma ç³»åˆ—

2. **ä¼˜åŒ–é…é¢ä½¿ç”¨**
   ```python
   # ä½¿ç”¨æµå¼è¾“å‡ºå‡å°‘ç­‰å¾…æ—¶é—´
   response = model.generate_content(prompt, stream=True)
   
   # è®¾ç½®åˆç†çš„ max_output_tokens
   generation_config = {"max_output_tokens": 512}
   
   # æ‰¹é‡å¤„ç†è¯·æ±‚
   prompts = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
   responses = [model.generate_content(p) for p in prompts]
   ```

3. **é”™è¯¯å¤„ç†å’Œé‡è¯•**
   ```python
   import time
   from google.api_core import retry
   
   @retry.Retry(predicate=retry.if_exception_type(Exception))
   def call_api_with_retry(prompt):
       return model.generate_content(prompt)
   
   try:
       response = call_api_with_retry("ä½ å¥½")
   except Exception as e:
       print(f"API è°ƒç”¨å¤±è´¥: {e}")
   ```

4. **ç›‘æ§é…é¢ä½¿ç”¨**
   ```python
   # è®°å½• API è°ƒç”¨
   import logging
   
   logging.basicConfig(level=logging.INFO)
   logger = logging.getLogger(__name__)
   
   def track_api_call(model, prompt):
       logger.info(f"è°ƒç”¨æ¨¡å‹: {model}")
       response = model.generate_content(prompt)
       logger.info(f"ä½¿ç”¨ tokens: {response.usage_metadata.total_token_count}")
       return response
   ```

5. **å®‰å…¨ç®¡ç† API å¯†é’¥**
   ```python
   # ä½¿ç”¨ç¯å¢ƒå˜é‡
   import os
   api_key = os.getenv('GOOGLE_AI_API_KEY')
   
   # æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶
   import json
   with open('config.json') as f:
       config = json.load(f)
       api_key = config['api_key']
   ```

### âš ï¸ é¿å…çš„åšæ³•

1. âŒ åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API å¯†é’¥
2. âŒ é¢‘ç¹å‘é€ç›¸åŒçš„è¯·æ±‚ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
3. âŒ å¿½ç•¥é€Ÿç‡é™åˆ¶ï¼ˆå®ç°é€€é¿é‡è¯•ï¼‰
4. âŒ ä¸å¤„ç†é”™è¯¯å’Œå¼‚å¸¸
5. âŒ ä½¿ç”¨è¿‡å¤§çš„ max_output_tokens

---

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. 403 é”™è¯¯ï¼šAPI key not valid

**åŸå› ï¼š**
- API å¯†é’¥é”™è¯¯æˆ–è¿‡æœŸ
- API æœªå¯ç”¨

**è§£å†³ï¼š**
```python {filename="Python"}
# æ£€æŸ¥ API å¯†é’¥
import google.generativeai as genai
genai.configure(api_key="YOUR_API_KEY")

# åˆ—å‡ºå¯ç”¨æ¨¡å‹ä»¥éªŒè¯
for model in genai.list_models():
    print(model.name)
```

### 2. 429 é”™è¯¯ï¼šResource exhausted

**åŸå› ï¼š**
- è¶…è¿‡é€Ÿç‡é™åˆ¶
- è¶…è¿‡æ¯æ—¥é…é¢

**è§£å†³ï¼š**
```python {filename="Python"}
import time
from google.api_core.exceptions import ResourceExhausted

def call_with_backoff(prompt, max_retries=3):
    for i in range(max_retries):
        try:
            return model.generate_content(prompt)
        except ResourceExhausted:
            if i < max_retries - 1:
                wait_time = 2 ** i  # æŒ‡æ•°é€€é¿
                print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
            else:
                raise
```

### 3. ç½‘ç»œè¶…æ—¶

**åŸå› ï¼š**
- ç½‘ç»œä¸ç¨³å®š
- è¯·æ±‚å†…å®¹è¿‡å¤§

**è§£å†³ï¼š**
```python {filename="Python"}
from google.api_core import timeout

# è®¾ç½®è¶…æ—¶
timeout_config = timeout.ExponentialTimeout(initial=30, maximum=120)
response = model.generate_content(prompt, timeout=timeout_config)
```

### 4. ä¸­å›½å¤§é™†è®¿é—®é—®é¢˜

**è§£å†³æ–¹æ³•ï¼š**
- ä½¿ç”¨ä»£ç†æˆ– VPN
- é…ç½®ä»£ç†ï¼š
  ```python
  import os
  os.environ['HTTP_PROXY'] = 'http://your-proxy:port'
  os.environ['HTTPS_PROXY'] = 'https://your-proxy:port'
  ```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨ç¼“å­˜

```python {filename="Python"}
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_api_call(prompt):
    return model.generate_content(prompt).text
```

### 2. æ‰¹é‡å¤„ç†

```python {filename="Python"}
import asyncio
from google.generativeai import GenerativeModel

async def batch_generate(prompts):
    model = GenerativeModel('gemini-2.5-flash')
    tasks = [model.generate_content_async(p) for p in prompts]
    return await asyncio.gather(*tasks)

# ä½¿ç”¨
prompts = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
responses = asyncio.run(batch_generate(prompts))
```

### 3. æµå¼å¤„ç†å¤§æ–‡æœ¬

```python {filename="Python"}
def process_large_text(text, chunk_size=10000):
    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
    results = []
    
    for chunk in chunks:
        response = model.generate_content(f"æ€»ç»“ï¼š{chunk}")
        results.append(response.text)
    
    return " ".join(results)
```

---

## ğŸ“š ç›¸å…³èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Google AI Studio å®Œæ•´ä»‹ç»](/providers/google-ai-studio)
- [Chatbot æœåŠ¡ä½¿ç”¨æŒ‡å—](/services/chatbot/google-ai-studio)
- [API å®˜æ–¹æ–‡æ¡£](https://ai.google.dev/docs)
- [API å‚è€ƒæ‰‹å†Œ](https://ai.google.dev/api)

### ä»£ç ç¤ºä¾‹
- [GitHub ç¤ºä¾‹åº“](https://github.com/google/generative-ai-docs)
- [Cookbook](https://github.com/google-gemini/cookbook)

### å­¦ä¹ èµ„æº
- [å¿«é€Ÿå…¥é—¨æ•™ç¨‹](https://ai.google.dev/tutorials/python_quickstart)
- [Prompt å·¥ç¨‹](https://ai.google.dev/docs/prompt_best_practices)
- [å‡½æ•°è°ƒç”¨æŒ‡å—](https://ai.google.dev/docs/function_calling)

---

**æœåŠ¡æä¾›è€…ï¼š** [Google AI Studio](/providers/google-ai-studio)
